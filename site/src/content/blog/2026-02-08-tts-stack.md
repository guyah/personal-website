---
title: "TTS in 2026: the stack from text to waveform (and where it breaks)"
description: "A systems view of modern neural TTS: normalization, phonemization, prosody, acoustic modeling, vocoders, and latency."
pubDate: 2026-02-08
tags: [tts, voice, systems]
icon: "üîä"
---

Text-to-speech is one of those problems that looks solved‚Äîuntil you try to ship it.

Modern neural TTS sounds great in demos, but production quality depends on a whole stack:

1. **Text normalization** (numbers, abbreviations, dates)
2. **Pronunciation / phonemization**
3. **Prosody** (durations, stress, intonation)
4. **Acoustic modeling** (text/phonemes ‚Üí mel or latent)
5. **Vocoder** (mel/latent ‚Üí waveform)
6. **Streaming + buffering**

This post is a tour of the stack with an emphasis on *failure modes*.

Plots generated by:

- `site/analysis/generate_all.py` (task: `tts_durations`)

## Prosody: durations are the first lever

Prosody is often described as ‚Äúexpressiveness,‚Äù but you can start with a simple proxy:

- durations by phoneme class
- distribution shifts across speaking styles

One compact visualization is a heatmap of duration percentiles by phoneme class (synthetic example):

![](/blog/2026-02-08-tts-stack/duration-percentiles-heatmap.svg)

Read it as:

- vowels tend to have longer durations
- stops tend to be shorter
- silence/pause durations dominate perceived rhythm

In production, duration control is how you avoid:

- rushed, machine-gun pacing
- weird pauses at commas
- monotone or overly sing-song intonation

## Where TTS breaks (in real products)

### 1) Text normalization failures

- ‚Äú1/2‚Äù ‚Üí ‚Äúone slash two‚Äù vs ‚Äúone half‚Äù
- ‚Äú‚Ç¨12.50‚Äù ‚Üí wrong currency or decimal reading
- times and dates

If you let the model guess, you‚Äôll ship embarrassing mistakes.

### 2) Pronunciation failures

Names, acronyms, and domain terms need:

- custom lexicons
- grapheme-to-phoneme overrides
- user-specific pronunciation adaptation (if allowed)

### 3) Latency and streaming

Voice UX is sensitive to:

- time-to-first-audio
- chunking artifacts
- buffering glitches

A strong TTS model that‚Äôs slow will feel worse than a slightly weaker model that‚Äôs fast and consistent.

## A minimal production checklist

- deterministic text normalization
- configurable pronunciation dictionary
- prosody controls (rate, pitch, emphasis)
- streaming vocoder path
- objective monitoring (dropouts, clipping, pacing)

## Reproduce

```bash
python site/analysis/generate_all.py
```

### TODO

- Add a section comparing unit selection vs neural TTS (and why the failure modes differ).
- Add simple audio examples (requires an audio pipeline in this repo).
