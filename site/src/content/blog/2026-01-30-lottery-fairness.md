---
title: "Is the lottery rigged? A fairness check you can reproduce"
description: "A practical, statistics-first way to sanity-check lottery draws: frequencies, chi-square, power, and what ‚Äòsuspicious‚Äô actually means."
pubDate: 2026-01-30
tags: [data-science, statistics, simulation]
icon: "üé≤"
---

When people ask *‚Äúis the lottery rigged?‚Äù* they usually mean one of two things:

1. **Some numbers appear too often** (frequency intuition).
2. **The process has a systematic bias** (a real mechanism).

This post is a reproducible template for checking both‚Äîwithout pretending we can prove anything from a small sample.

All plots in this post are generated by:

- `site/analysis/generate_all.py` (task: `lottery_fairness`)

## The mental model: what does ‚Äúfair‚Äù predict?

Let‚Äôs use an idealized **6/49** lottery (6 numbers drawn without replacement from 1..49).

Across many draws:

- Each ball should appear about the same number of times.
- The *deviations* should look like random noise.

If you run the process long enough, every ball will look ‚Äúhot‚Äù or ‚Äúcold‚Äù at some point. The question is: *are the deviations consistent with chance?*

## Step 1 ‚Äî frequency deviations (the picture people actually care about)

In a fair simulation with 25,000 draws, the deviations from the expected count look like this:

![](/blog/2026-01-30-lottery-fairness/freq-deviation-fair.svg)

A few key notes:

- The deviations are centered around zero.
- Some bars are positive, some negative.
- The spread is not ‚Äúsmall‚Äù: random variation is *supposed* to be visible.

This plot is the antidote to the *‚Äúbut number 17 came up 12 times this month!‚Äù* argument. The deviation plot is **what random looks like**, once you‚Äôve seen enough of it.

## Step 2 ‚Äî a simple global test (chi-square) and p-values

A classic global test for categorical frequencies is the **chi-square goodness-of-fit test**.

- Null hypothesis: each ball is equally likely (in expectation).
- Test statistic: how far observed counts deviate from expected counts.

Rather than compute one p-value and over-interpret it, I like to check **how p-values behave under fairness**: if the system is fair, p-values across repeated experiments should be roughly uniform on [0, 1].

Here‚Äôs the p-value histogram from many independent fair experiments (each experiment = 2,000 draws):

![](/blog/2026-01-30-lottery-fairness/pvalues-fair.svg)

If you‚Äôve never internalized p-values, this is the intuition-builder: under a true null, the p-values don‚Äôt cluster near 0.

## Step 3 ‚Äî what a small bias looks like (and why you might still miss it)

Now we simulate a biased mechanism: one ball is very slightly favored (here, ball 13 has a 12% weight increase in a simplified sequential-with-weights drawing model).

![](/blog/2026-01-30-lottery-fairness/freq-deviation-biased.svg)

Two important conclusions follow:

1. **Bias is detectable** if you have enough draws.
2. **Small bias is hard** if you don‚Äôt.

This is the core reason lottery conspiracy discussions go nowhere: people bring a handful of draws to a question that requires *thousands*.

## A practical checklist for real lottery data

If you want to apply this to a real lottery dataset:

1. **Get the raw draws** (date + numbers). Don‚Äôt use screenshots.
2. **Compute counts** for each ball.
3. **Plot deviation-from-expected**.
4. **Run a global test** (chi-square is fine as a first pass).
5. **Adjust your expectations for multiple comparisons**:
   - If you stare at 49 balls, one of them will look weird.
6. **Look for mechanisms**:
   - Do certain balls share manufacturing batches?
   - Is there a difference across machines, venues, seasons?

## The uncomfortable truth: ‚Äúsuspicious‚Äù is not a statistic

Humans are very good at seeing patterns. Randomness produces patterns too.

A useful working definition:

> ‚ÄúSuspicious‚Äù means a deviation that is both **statistically unlikely under a fair model** and **mechanistically plausible**.

If you only have one of those, you don‚Äôt have much.

## Reproduce

From repo root:

```bash
python3 -m venv .venv
source .venv/bin/activate
pip install -r site/analysis/requirements.txt
python site/analysis/generate_all.py
```

### TODO (if I extend this post)

- Add a section on **serial correlation** (e.g., do some numbers co-occur too often?).
- Add a Bayesian framing: *how strong is the evidence for small bias?*
- Swap the toy weighted model for a more realistic physical-bias model.
