---
title: "Why your context window feels smaller than it is"
description: "Token budgets are an engineering constraint: measure, allocate, and design for the tail. Real measurements included."
pubDate: 2026-02-02
tags: [llm, engineering]
icon: "ğŸ§¾"
---

## TL;DR

- Budgeting is a **composition** problem (system + history + retrieval + response).
- Design for **p95/p99**, not the mean â€” tails create user-visible failures.
- â€œ~4 chars/tokenâ€ is a planning heuristic only after you validate it on your own traffic.

A 32k context window sounds enormousâ€¦ until you build a system that uses it.

Then you discover the recurring failure mode:

- prompt templates grow
- conversation history grows
- retrieved documents grow
- guardrails grow

â€¦and suddenly youâ€™re truncating the one part you cared about.

Plots generated by:

- `site/analysis/generate_all.py` (task: `token_budgets`)

## Rule-of-thumb: chars per token (real measurement)

You canâ€™t reason about budgets in characters. Tokenizers arenâ€™t fixed-width.

But for rough planning, an English-ish heuristic is:

> **~4 characters per token** (including spaces/punctuation, averaged)

On real prompts (measured via API usage), hereâ€™s what the ratio looks like:

![](/blog/2026-02-02-token-budgets/chars-per-token.svg)

### Numbers

| Item | Value |
|---|---|
| Measured median | ~2.84 chars/token (small sample; content-dependent) |
| Rule of thumb | ~4 chars/token (planning only) |

## The real issue: budget composition

What matters operationally isnâ€™t â€œdo we have 32k tokens?â€

Itâ€™s:

- how many tokens are reserved for system/tooling
- how many go to history
- how many go to retrieval
- how many must remain for the modelâ€™s response

A small-sample distribution of prompt token counts from the measurement set:

![](/blog/2026-02-02-token-budgets/prompt-size-hist.svg)

## What I actually do in production

- Set explicit caps per component (system/history/retrieval/response).
- Measure p95/p99 and treat overflows as an incident, not a warning.
- Compress history intentionally (summaries), donâ€™t silently drop the latest user message.
- RAG is the usual budget killer: reduce docs, reduce chunk size, and raise precision.

## A practical budget template (32k window)

- **System/tooling:** 1kâ€“2k
- **Conversation history:** 6kâ€“12k (summarize beyond that)
- **Retrieval:** 8kâ€“14k (hard cap)
- **Response headroom:** 2kâ€“6k (or youâ€™ll clip the answer)

If you donâ€™t set these caps, your system will set them for you â€” by truncating something important.

## Reproduce

```bash
python site/analysis/generate_all.py
```
